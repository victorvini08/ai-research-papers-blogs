app = "ai-research-blogs"
primary_region = "sin"
kill_signal = "SIGINT"
kill_timeout = 5

[build]
  dockerfile = "Dockerfile"

[env]
  PORT = "8080"
  FLASK_ENV = "production"
  CUDA_VISIBLE_DEVICES = ""
  TORCH_CUDA_AVAILABLE = "false"
  CUDA_DEVICE_ORDER = "PCI_BUS_ID"
  PYTORCH_CUDA_ALLOC_CONF = "max_split_size_mb:128"
  DATABASE_PATH = "/data/papers.db"

[http_service]
  internal_port = 8080
  force_https = true
  auto_stop_machines = false
  auto_start_machines = true
  min_machines_running = 1

[[mounts]]
  source = "data"
  destination = "/data"
